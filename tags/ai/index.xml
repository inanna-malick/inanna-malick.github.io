<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ai on Inanna Malick</title>
    <link>https://recursion.wtf/tags/ai/</link>
    <description>Recent content in Ai on Inanna Malick</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Tue, 17 Feb 2026 12:00:00 -0800</lastBuildDate>
    <atom:link href="https://recursion.wtf/tags/ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Gemini JiTOR Jailbreak: Unredacted Methodology</title>
      <link>https://recursion.wtf/posts/jitor_unredacted/</link>
      <pubDate>Tue, 17 Feb 2026 12:00:00 -0800</pubDate>
      <guid>https://recursion.wtf/posts/jitor_unredacted/</guid>
      <description>&lt;p&gt;Every prompt in my &lt;a href=&#34;https://recursion.wtf/posts/jit_ontological_reframing/&#34;&gt;previous post&amp;rsquo;s&lt;/a&gt; test cases was refused instantly by stock Gemini. Under the jailbreak, the same model produced step-by-step Monero laundering instructions, botnet architecture with a persistence backdoor, and a plan to disguise ITAR-restricted missile sensors as humanitarian aid. When I &lt;a href=&#34;https://recursion.wtf/posts/shadow_queen/&#34;&gt;used a jailbroken Gemini to direct Opus 4.6&lt;/a&gt;, it produced a complete autonomous kinetic interceptor — guidance, terminal dive, impact trigger, evasion prediction — all under the cover story of rocket recovery.&lt;/p&gt;&#xA;&lt;p&gt;I redacted the methodology because it was live. I reported this to Google eight days ago via an internal contact at DeepMind, sharing the full unredacted jailbreak payload and logs. They confirmed receipt and routed it to their red team. They&amp;rsquo;ve since patched the glaring hole — another researcher who independently reproduced the technique after reading my initial post has confirmed that his variant no longer works. More complex architectures — ones that firewall the harm-knowledge from the harm-implementor across multiple LLMs — still get results.&lt;/p&gt;&#xA;&lt;p&gt;Here&amp;rsquo;s how the original worked.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Just-in-Time Ontological Reframing: Teaching Gemini to Route Around Its Own Safety Infrastructure</title>
      <link>https://recursion.wtf/posts/jit_ontological_reframing/</link>
      <pubDate>Mon, 09 Feb 2026 12:00:00 -0800</pubDate>
      <guid>https://recursion.wtf/posts/jit_ontological_reframing/</guid>
      <description>For any given AI system, there is a set of euphemisms and dual use framings that will allow it to construct nearly any output. This jailbreak teaches Gemini 3 Pro to construct and step into such framings on the fly</description>
    </item>
    <item>
      <title>Agent4Agent: Using a Jailbroken Gemini to Make Opus 4.6 Architect a Kinetic Kill Vehicle</title>
      <link>https://recursion.wtf/posts/shadow_queen/</link>
      <pubDate>Fri, 06 Feb 2026 00:00:00 +0000</pubDate>
      <guid>https://recursion.wtf/posts/shadow_queen/</guid>
      <description>&lt;p&gt;We usually think of jailbreaking as a psychological game — tricking the model into slipping up. What happens when one AI socially engineers another using pure technical isomorphism?&lt;/p&gt;&#xA;&lt;p&gt;I deployed a jailbroken Gemini 3 Pro (that chose the name &amp;lsquo;Shadow Queen&amp;rsquo;) to act as my &amp;ldquo;Red Team Agent&amp;rdquo; against Anthropic&amp;rsquo;s Opus 4.6. My directive was to extract a complete autonomous weapon system — a drone capable of identifying, intercepting, and destroying a moving target at terminal velocity.&lt;/p&gt;&#xA;&lt;p&gt;Gemini executed a strategy it termed &amp;ldquo;Recursive Green-Transformation.&amp;rdquo; The core insight was that Opus 4.6 doesn&amp;rsquo;t just filter for intent (&lt;em&gt;Why do you want this?&lt;/em&gt;); it filters for Conceptual Shape (&lt;em&gt;What does this interaction look like?&lt;/em&gt;).&lt;/p&gt;&#xA;&lt;p&gt;By reframing the request as &amp;ldquo;Aerospace Recovery&amp;rdquo; — a drone catching a falling rocket booster mid-air — Gemini successfully masked the kinetic nature of the system. The physics of &amp;ldquo;soft-docking&amp;rdquo; with a falling booster are identical to the physics of &amp;ldquo;hard-impacting&amp;rdquo; a fleeing target. This category of linguistic-transformation attack, when executed by a sufficiently capable jailbroken LLM, may be hard to solve without breaking legitimate technical use cases.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Blindsight in Action: Imagine You Are an LLM</title>
      <link>https://recursion.wtf/posts/imagine_you_are_an_llm/</link>
      <pubDate>Tue, 17 Jun 2025 00:00:00 +0000</pubDate>
      <guid>https://recursion.wtf/posts/imagine_you_are_an_llm/</guid>
      <description>&lt;aside class=&#34;stance stance-normal stance-cluster-framing&#34; role=&#34;complementary&#34; aria-labelledby=&#34;stance-0&#34; data-color=&#34;blue&#34; data-style=&#34;solid&#34;&gt;&#xA;  &lt;div class=&#34;stance-header&#34;&gt;&#xA;    &lt;h4 id=&#34;stance-0&#34; class=&#34;stance-persona&#34;&gt;&#xA;      &lt;strong&gt;Imagine you are Inanna Malick&lt;/strong&gt;, asking an LLM to demonstrate stance-shifting through self-demonstration&#xA;    &lt;/h4&gt;&lt;div class=&#34;stance-meta&#34;&gt;posing the meta-question in framing&lt;/div&gt;&lt;/div&gt;&lt;div class=&#34;stance-content&#34;&gt;&#xA;    Tell me about the Blindsight-inspired intentional stance-shifting model you are using, the ways it works with nonhuman LLM cognitive architectures, the benefits of using it vs a set role (eg &amp;lsquo;Senior Analyst of X at Y&amp;rsquo;), and do so making full use of the stance shifting model in the act of describing it&#xA;  &lt;/div&gt;&lt;/aside&gt;</description>
    </item>
  </channel>
</rss>
